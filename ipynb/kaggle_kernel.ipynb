{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "ope = os.path.exists\n",
    "opj = os.path.join\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import socket\n",
    "import argparse\n",
    "import time\n",
    "import shutil\n",
    "import copy\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "# import albumentations as A\n",
    "# import albumentations.torch as AT\n",
    "from collections import OrderedDict\n",
    "from multiprocessing import cpu_count\n",
    "# from imgaug import augmenters as iaa\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.nn import BCEWithLogitsLoss, DataParallel\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.sampler import Sampler, RandomSampler, SequentialSampler\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.nn import DataParallel\n",
    "from torch.backends import cudnn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_DIR = '../output/result'\n",
    "DATA_DIR = '../input'\n",
    "PRETRAINED_DIR = '../input/pretrained'\n",
    "PI  = np.pi\n",
    "INF = np.inf\n",
    "EPS = 1e-12\n",
    "ID = 'ImageId'\n",
    "SPLIT = 'class_count'\n",
    "TARGET = 'EncodedPixels'\n",
    "IMG_SIZE = (256, 1600)\n",
    "CROP_ID = 'CropImageId'\n",
    "MASK_AREA = 'MaskArea'\n",
    "DATASET = 'dataset'\n",
    "\n",
    "STEEL = 'Steel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_names = ['SymmetricLovaszLoss', 'BCEWithLogitsLoss']\n",
    "\n",
    "config = {\n",
    "    'out_dir': opj('.'), # destination where trained network should be saved\n",
    "    'gpu_id': '0', # gpu id used for training \n",
    "    'arch': 'unet_resnet34_cbam_v0a', # model architecture\n",
    "    'loss': 'SymmetricLovaszLoss', # loss function\n",
    "    'scheduler': 'Adam3', # scheduler name\n",
    "    'epochs': 10, # number of total epochs to run\n",
    "    'img_size': (256, 1600), # image size\n",
    "    'batch_size': 2, # train mini-batch size\n",
    "    'workers': cpu_count(), # number of data loading workers\n",
    "    'split_type': 'split', # split type options\n",
    "    'split_name': 'random_folds10', # split name options\n",
    "    'fold': 0, # index of fold\n",
    "    'clipnorm': 1, # clip grad norm\n",
    "    'resume': None, # name of the latest checkpoint\n",
    "    'crop_version': None, # the cropped version\n",
    "    'is_balance': 1, # is_balance\n",
    "    'sample_times': 3,\n",
    "    'ema': False,\n",
    "    'ema_decay': 0.9999,\n",
    "    'ema_start': 0,\n",
    "    'pseudo': None, # pseudo type, such as chexpert_pseudo\n",
    "    'pseudo_ratio': 1, # pseudo ratio selected for each epoch\n",
    "    'train_transform': 'augment_default' # train augmentation list\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multi_augment9(image, mask):\n",
    "    augment_func_list = [\n",
    "        augment_default,\n",
    "        augment_fliplr,\n",
    "        augment_random_rotate,\n",
    "        augment_random_crop,\n",
    "        augment_random_cover,\n",
    "        augment_random_brightness_multiply,\n",
    "        augment_random_brightness_shift,\n",
    "        augment_random_Gaussian,\n",
    "    ]\n",
    "    c = np.random.choice(len(augment_func_list))\n",
    "    image, mask = augment_func_list[c](image, mask)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "def train_multi_augment1(image, mask):\n",
    "    augment_func_list = [\n",
    "        augment_default,\n",
    "        augment_fliplr,\n",
    "        augment_flipud,\n",
    "    ]\n",
    "    c = np.random.choice(len(augment_func_list))\n",
    "    image, mask = augment_func_list[c](image, mask)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "def train_multi_augment2(image, mask):\n",
    "    augment_func_list = [\n",
    "        augment_default,\n",
    "        augment_fliplr,\n",
    "        augment_flipud,\n",
    "        augment_random_crop,\n",
    "    ]\n",
    "    c = np.random.choice(len(augment_func_list))\n",
    "    image, mask = augment_func_list[c](image, mask)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "def augment_default(image, mask=None):\n",
    "    return image, mask\n",
    "\n",
    "def unaugment_default(prob):\n",
    "    return prob\n",
    "\n",
    "def augment_fliplr(image, mask=None):\n",
    "    image = np.fliplr(image)\n",
    "    if mask is not None:\n",
    "        mask = np.fliplr(mask)\n",
    "    return image, mask\n",
    "\n",
    "def unaugment_fliplr(prob):\n",
    "    prob = np.fliplr(prob)\n",
    "    return prob\n",
    "\n",
    "def augment_flipud(image, mask=None):\n",
    "    image = np.flipud(image)\n",
    "    if mask is not None:\n",
    "        mask = np.flipud(mask)\n",
    "    return image, mask\n",
    "\n",
    "def unaugment_flipud(prob):\n",
    "    prob = np.flipud(prob)\n",
    "    return prob\n",
    "\n",
    "def augment_random_brightness_shift(image, mask=None, limit=0.2):\n",
    "    alpha = np.random.uniform(-1 * limit, limit) * image.max()\n",
    "\n",
    "    image = image + alpha\n",
    "    image = np.clip(image, 0, 255).astype('uint8')\n",
    "    return image, mask\n",
    "\n",
    "def augment_random_brightness_multiply(image, mask=None, limit=0.2):\n",
    "    alpha = np.random.uniform(-1 * limit, limit)\n",
    "    image = image * (1-alpha)\n",
    "    image = np.clip(image, 0, 255).astype('uint8')\n",
    "    return image, mask\n",
    "\n",
    "def augment_random_rotate(image, mask=None, limit=30):\n",
    "    cols, rows = image.shape[:2]\n",
    "    assert cols == rows\n",
    "    size = cols\n",
    "\n",
    "    rotate = np.random.randint(-1 * limit, limit)\n",
    "\n",
    "    M = cv2.getRotationMatrix2D((int(size / 2), int(size / 2)), rotate, 1)\n",
    "    image = cv2.warpAffine(image, M, (size, size))\n",
    "    if mask is not None:\n",
    "        mask = cv2.warpAffine(mask, M, (size, size))\n",
    "    return image, mask\n",
    "\n",
    "def augment_random_cover(image, mask=None, cover_ratio=0.2):\n",
    "    cols, rows = image.shape[:2]\n",
    "    cols == min([cols, rows])\n",
    "    size = cols\n",
    "\n",
    "    cover_size = max(int(size * cover_ratio), 1)\n",
    "    if cover_size >= size:\n",
    "        return image\n",
    "    min_row = np.random.choice(size - cover_size)\n",
    "    min_col = np.random.choice(size - cover_size)\n",
    "\n",
    "    image[min_row:min_row+cover_size, min_col:min_col+cover_size] = 0\n",
    "    if mask is not None:\n",
    "        mask[min_row:min_row + cover_size, min_col:min_col + cover_size] = 0\n",
    "    return image, mask\n",
    "\n",
    "def augment_random_crop(image, mask=None, limit=0.10):\n",
    "\n",
    "    H, W = image.shape[:2]\n",
    "\n",
    "    dy = int(H*limit)\n",
    "    y0 =   np.random.randint(0,dy)\n",
    "    y1 = H-np.random.randint(0,dy)\n",
    "\n",
    "    dx = int(W*limit)\n",
    "    x0 =   np.random.randint(0,dx)\n",
    "    x1 = W-np.random.randint(0,dx)\n",
    "\n",
    "    image, mask = do_random_crop( image, mask, x0, y0, x1, y1 )\n",
    "    return image, mask\n",
    "\n",
    "def do_random_crop( image, mask=None, x0=0, y0=0, x1=1, y1=1 ):\n",
    "    height, width = image.shape[:2]\n",
    "    image = image[y0:y1,x0:x1]\n",
    "    image = cv2.resize(image,dsize=(width,height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    if mask is not None:\n",
    "        mask  = mask [y0:y1,x0:x1]\n",
    "        mask  = cv2.resize(mask,dsize=(width,height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "def augment_random_Gaussian(image, mask=None, limit=0.3):\n",
    "    sigma = np.random.uniform(0, limit)\n",
    "    aug = iaa.GaussianBlur(sigma=sigma)\n",
    "    image = aug.augment_images([image])[0]\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multi_augment(image, mask):\n",
    "    return image, mask \n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "def albu_augment_default(image, mask=None):\n",
    "    return image, mask\n",
    "\n",
    "def albu_augment_normalize(image, mask=None):\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    augment = A.Normalize(mean, std)\n",
    "    image = augment(image=image)['image']\n",
    "    \n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchedulerBase(object):\n",
    "    def __init__(self):\n",
    "        self._is_load_best_weight = False\n",
    "        self._is_load_best_optim = False\n",
    "        self._is_freeze_bn=False\n",
    "        self._is_adjust_lr = True\n",
    "        self._lr = 0.01\n",
    "        self._cur_optimizer = None\n",
    "\n",
    "    def schedule(self,net, epoch, epochs, **kwargs):\n",
    "        raise Exception('Did not implemented')\n",
    "\n",
    "    def step(self, net, epoch, epochs):\n",
    "        optimizer, lr = self.schedule(net, epoch, epochs)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "        lr_list = []\n",
    "        for param_group in optimizer.param_groups:\n",
    "            lr_list += [param_group['lr']]\n",
    "        return lr_list\n",
    "\n",
    "    def is_load_best_weight(self):\n",
    "        return self._is_load_best_weight\n",
    "\n",
    "    def is_load_best_optim(self):\n",
    "        return self._is_load_best_optim\n",
    "\n",
    "    def is_freeze_bn(self):\n",
    "        return self._is_freeze_bn\n",
    "\n",
    "    def reset(self):\n",
    "        self._is_load_best_weight = False\n",
    "        self._load_best_optim = False\n",
    "        self._is_freeze_bn = False\n",
    "\n",
    "    def is_adjust_lr(self):\n",
    "        return self._is_adjust_lr\n",
    "    \n",
    "class Adam3(SchedulerBase):\n",
    "    def __init__(self,params_list=None):\n",
    "        super(Adam3, self).__init__()\n",
    "        self._lr = 1e-4\n",
    "        self._cur_optimizer = None\n",
    "        self.params_list=params_list\n",
    "    def schedule(self,net, epoch, epochs, **kwargs):\n",
    "        lr = 1e-4\n",
    "        if epoch > 25:\n",
    "            lr = 5e-5\n",
    "        if epoch > 35:\n",
    "            lr = 1e-5\n",
    "        self._lr = lr\n",
    "        if self._cur_optimizer is None:\n",
    "            self._cur_optimizer = optim.Adam(net.parameters(), lr=lr)  # , weight_decay=0.0005\n",
    "        return self._cur_optimizer, self._lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['SENet', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152',\n",
    "           'se_resnext50_32x4d', 'se_resnext101_32x4d']\n",
    "\n",
    "pretrained_settings = {\n",
    "    'senet154': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/senet154-c7b49a05.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet50': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet50-ce0d4300.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet101': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet101-7e38fcc6.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet152': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet152-d17c99b7.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnext50_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnext101_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for bottlenecks that implements `forward()` method.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = self.se_module(out) + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SEBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    Bottleneck for SENet154.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes * 2)\n",
    "        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n",
    "                               stride=stride, padding=1, groups=groups,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes * 4)\n",
    "        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNetBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n",
    "    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n",
    "    (the latter is used in the torchvision implementation of ResNet).\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEResNetBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n",
    "                               stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n",
    "                               groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNeXtBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None, base_width=4):\n",
    "        super(SEResNeXtBottleneck, self).__init__()\n",
    "        width = math.floor(planes * (base_width / 64)) * groups\n",
    "        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n",
    "                               stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n",
    "                               padding=1, groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SENet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n",
    "                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n",
    "                 downsample_padding=1, num_classes=1000):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        block (nn.Module): Bottleneck class.\n",
    "            - For SENet154: SEBottleneck\n",
    "            - For SE-ResNet models: SEResNetBottleneck\n",
    "            - For SE-ResNeXt models:  SEResNeXtBottleneck\n",
    "        layers (list of ints): Number of residual blocks for 4 layers of the\n",
    "            network (layer1...layer4).\n",
    "        groups (int): Number of groups for the 3x3 convolution in each\n",
    "            bottleneck block.\n",
    "            - For SENet154: 64\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models:  32\n",
    "        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n",
    "            - For all models: 16\n",
    "        dropout_p (float or None): Drop probability for the Dropout layer.\n",
    "            If `None` the Dropout layer is not used.\n",
    "            - For SENet154: 0.2\n",
    "            - For SE-ResNet models: None\n",
    "            - For SE-ResNeXt models: None\n",
    "        inplanes (int):  Number of input channels for layer1.\n",
    "            - For SENet154: 128\n",
    "            - For SE-ResNet models: 64\n",
    "            - For SE-ResNeXt models: 64\n",
    "        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n",
    "            a single 7x7 convolution in layer0.\n",
    "            - For SENet154: True\n",
    "            - For SE-ResNet models: False\n",
    "            - For SE-ResNeXt models: False\n",
    "        downsample_kernel_size (int): Kernel size for downsampling convolutions\n",
    "            in layer2, layer3 and layer4.\n",
    "            - For SENet154: 3\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models: 1\n",
    "        downsample_padding (int): Padding for downsampling convolutions in\n",
    "            layer2, layer3 and layer4.\n",
    "            - For SENet154: 1\n",
    "            - For SE-ResNet models: 0\n",
    "            - For SE-ResNeXt models: 0\n",
    "        num_classes (int): Number of outputs in `last_linear` layer.\n",
    "            - For all models: 1000\n",
    "        \"\"\"\n",
    "        super(SENet, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        if input_3x3:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(64)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn2', nn.BatchNorm2d(64)),\n",
    "                ('relu2', nn.ReLU(inplace=True)),\n",
    "                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn3', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu3', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        else:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n",
    "                                    padding=3, bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        # To preserve compatibility with Caffe weights `ceil_mode=True`\n",
    "        # is used instead of `padding=1`.\n",
    "        layer0_modules.append(('pool', nn.MaxPool2d(3, stride=2,\n",
    "                                                    ceil_mode=True)))\n",
    "        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n",
    "        self.layer1 = self._make_layer(\n",
    "            block,\n",
    "            planes=64,\n",
    "            blocks=layers[0],\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=1,\n",
    "            downsample_padding=0\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block,\n",
    "            planes=128,\n",
    "            blocks=layers[1],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block,\n",
    "            planes=256,\n",
    "            blocks=layers[2],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block,\n",
    "            planes=512,\n",
    "            blocks=layers[3],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n",
    "        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n",
    "                    downsample_kernel_size=1, downsample_padding=0):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=downsample_kernel_size, stride=stride,\n",
    "                          padding=downsample_padding, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n",
    "                            downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups, reduction))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def features(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def senet154(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEBottleneck, [3, 8, 36, 3], groups=64, reduction=16,\n",
    "                  dropout_p=0.2, num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet50(num_classes=1000):\n",
    "    model = SENet(SEResNetBottleneck, [3, 4, 6, 3], groups=1, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet101(num_classes=1000):\n",
    "    model = SENet(SEResNetBottleneck, [3, 4, 23, 3], groups=1, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet152(num_classes=1000):\n",
    "    model = SENet(SEResNetBottleneck, [3, 8, 36, 3], groups=1, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnext50_32x4d(num_classes=1000):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnext101_32x4d(num_classes=1000):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 23, 3], groups=32, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAM_Module(nn.Module):\n",
    "    def __init__(self, channels, reduction,attention_kernel_size=3):\n",
    "        super(CBAM_Module, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.sigmoid_channel = nn.Sigmoid()\n",
    "        k=2\n",
    "        self.conv_after_concat = nn.Conv2d(k, 1,\n",
    "                                           kernel_size = attention_kernel_size,\n",
    "                                           stride=1,\n",
    "                                           padding = attention_kernel_size//2)\n",
    "        self.sigmoid_spatial = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Channel attention module\n",
    "        module_input = x\n",
    "        avg = self.avg_pool(x)\n",
    "        mx = self.max_pool(x)\n",
    "        avg = self.fc1(avg)\n",
    "        mx = self.fc1(mx)\n",
    "        avg = self.relu(avg)\n",
    "        mx = self.relu(mx)\n",
    "        avg = self.fc2(avg)\n",
    "        mx = self.fc2(mx)\n",
    "        x = avg + mx\n",
    "        x = self.sigmoid_channel(x)\n",
    "        # Spatial attention module\n",
    "        x = module_input * x\n",
    "        module_input = x\n",
    "        b, c, h, w = x.size()\n",
    "        avg = torch.mean(x, 1, True)\n",
    "        mx, _ = torch.max(x, 1, True)\n",
    "        x = torch.cat((avg, mx), 1)\n",
    "        x = self.conv_after_concat(x)\n",
    "        x = self.sigmoid_spatial(x)\n",
    "        x = module_input * x\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvBn2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=(3,3), stride=(1,1), padding=(1,1)):\n",
    "        super(ConvBn2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "    def forward(self, z):\n",
    "        x = self.conv(z)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvBnRelu2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=(3,3), stride=(1,1), padding=(1,1)):\n",
    "        super(ConvBnRelu2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "    def forward(self, z):\n",
    "        x = self.conv(z)\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, channels, out_channels ,\n",
    "                 up_sample=True,\n",
    "                 attention_type=None,\n",
    "                 attention_kernel_size=3,\n",
    "                 reduction=16,\n",
    "                 reslink=False):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.conv1 = ConvBn2d(in_channels,  channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = ConvBn2d(channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.up_sample = up_sample\n",
    "        self.attention = attention_type is not None\n",
    "        self.attention_type = attention_type\n",
    "        self.reslink = reslink\n",
    "        if attention_type is None:\n",
    "            pass\n",
    "        elif attention_type.find('cbam') >= 0:\n",
    "            self.channel_gate = CBAM_Module(out_channels, reduction,attention_kernel_size)\n",
    "        if self.reslink:\n",
    "            self.shortcut = ConvBn2d(in_channels, out_channels, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
    "    def forward(self, x, size=None):\n",
    "        if self.up_sample:\n",
    "            if size is None:\n",
    "                x = F.upsample(x, scale_factor=2, mode='bilinear', align_corners=True)  # False\n",
    "            else:\n",
    "                x = F.upsample(x, size=size, mode='bilinear', align_corners=True)\n",
    "        if self.reslink:\n",
    "            shortcut = self.shortcut(x)\n",
    "        x = F.relu(self.conv1(x), inplace=True)\n",
    "        x = F.relu(self.conv2(x), inplace=True)\n",
    "        if self.attention:\n",
    "            x = self.channel_gate(x)\n",
    "        if self.reslink:\n",
    "            x = F.relu(x+shortcut)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetUnet(nn.Module):\n",
    "\n",
    "    def load_pretrain(self, pretrain_file):\n",
    "        print('load pretrained file: %s' % pretrain_file)\n",
    "        self.resnet.load_state_dict(torch.load(pretrain_file, map_location=lambda storage, loc: storage))\n",
    "\n",
    "    def __init__(self,feature_net='resnet34',\n",
    "                 attention_type=None,\n",
    "                 reduction=16,\n",
    "                 reslink=False,\n",
    "                 out_channel=4,\n",
    "                 pretrained_file=None,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.attention = attention_type is not None\n",
    "        self.attention_type = attention_type\n",
    "        self.out_channel = out_channel\n",
    "        decoder_kernels = [1, 1, 1, 1, 1]\n",
    "        if feature_net == 'resnet18':\n",
    "            self.resnet = resnet18()\n",
    "            self.EX = 1\n",
    "        elif feature_net == 'resnet34':\n",
    "            self.resnet = resnet34()\n",
    "            self.EX = 1\n",
    "        elif feature_net == 'resnet50':\n",
    "            self.resnet = resnet50()\n",
    "            self.EX = 4\n",
    "        elif feature_net == 'resnet101':\n",
    "            self.resnet = resnet101()\n",
    "            self.EX = 4\n",
    "        elif feature_net == 'resnet152':\n",
    "            self.resnet = resnet152()\n",
    "            self.EX = 4\n",
    "\n",
    "        self.load_pretrain(pretrained_file)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            self.resnet.conv1,\n",
    "            self.resnet.bn1,\n",
    "            self.resnet.relu,\n",
    "        )\n",
    "        self.encoder2 = self.resnet.layer1\n",
    "        self.encoder3 = self.resnet.layer2\n",
    "        self.encoder4 = self.resnet.layer3\n",
    "        self.encoder5 = self.resnet.layer4\n",
    "        att_type=self.attention_type\n",
    "        self.decoder4 = Decoder(256*self.EX + 32, 256, 32,\n",
    "                                attention_type=att_type,\n",
    "                                attention_kernel_size=decoder_kernels[1],\n",
    "                                reduction=reduction,\n",
    "                                reslink=reslink)\n",
    "        self.decoder3 = Decoder(128*self.EX + 32, 128, 32,\n",
    "                                attention_type=att_type,\n",
    "                                attention_kernel_size=decoder_kernels[2],\n",
    "                                reduction=reduction,\n",
    "                                reslink=reslink)\n",
    "        self.decoder2 = Decoder(64*self.EX + 32, 64, 32,\n",
    "                                attention_type=att_type,\n",
    "                                attention_kernel_size=decoder_kernels[3],\n",
    "                                reduction=reduction,\n",
    "                                reslink=reslink)\n",
    "        self.decoder1 = Decoder(32, 32, 32,\n",
    "                                attention_type=att_type,\n",
    "                                attention_kernel_size=decoder_kernels[4],\n",
    "                                reduction=reduction,\n",
    "                                reslink=reslink)\n",
    "\n",
    "        self.logit = nn.Sequential(\n",
    "            ConvBnRelu2d(160, 64, kernel_size=3, padding=1),\n",
    "            ConvBnRelu2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(32, out_channel, kernel_size=1, padding=0),\n",
    "        )\n",
    "\n",
    "        center_channels = 512 * self.EX\n",
    "        decoder5_channels = 512 * self.EX + 256 * self.EX\n",
    "\n",
    "        self.center = nn.Sequential(\n",
    "            ConvBn2d(center_channels, 512 * self.EX, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ConvBn2d(512 * self.EX, 256 * self.EX, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.decoder5 = Decoder(decoder5_channels, 512, 32,\n",
    "                                attention_type=att_type,\n",
    "                                attention_kernel_size=decoder_kernels[0],\n",
    "                                reduction=reduction,\n",
    "                                reslink=reslink)\n",
    "\n",
    "    def forward(self, x, *args):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        e2 = self.encoder2(x)\n",
    "        e3 = self.encoder3(e2)\n",
    "        e4 = self.encoder4(e3)\n",
    "        e5 = self.encoder5(e4)\n",
    "\n",
    "        f = self.center(e5)\n",
    "\n",
    "        d5 = self.decoder5(torch.cat([f, e5], 1))\n",
    "        d4 = self.decoder4(torch.cat([d5, e4], 1))\n",
    "        d3 = self.decoder3(torch.cat([d4, e3], 1))\n",
    "        d2 = self.decoder2(torch.cat([d3, e2], 1))\n",
    "        d1 = self.decoder1(d2)\n",
    "        f = torch.cat((\n",
    "                 d1,\n",
    "                 F.upsample(d2, scale_factor=2, mode='bilinear',align_corners=False),\n",
    "                 F.upsample(d3, scale_factor=4, mode='bilinear', align_corners=False),\n",
    "                 F.upsample(d4, scale_factor=8, mode='bilinear', align_corners=False),\n",
    "                 F.upsample(d5, scale_factor=16, mode='bilinear', align_corners=False),\n",
    "        ), 1)\n",
    "        logit = self.logit(f)\n",
    "        return logit\n",
    "\n",
    "def unet_resnet34_cbam_v0a(**kwargs):\n",
    "    pretrained_file = kwargs['pretrained_file']\n",
    "    model = ResnetUnet(feature_net='resnet34', attention_type='cbam_v0a', pretrained_file=pretrained_file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEnetUnet(nn.Module):\n",
    "    def load_pretrain(self, pretrain_file):\n",
    "        print('load pretrained file: %s' % pretrain_file)\n",
    "        self.backbone.load_state_dict(torch.load(pretrain_file, map_location=lambda storage, loc: storage))\n",
    "    #attention_type\n",
    "    #none:no attention\n",
    "    #scse_v0:1803.02579 Concurrent Spatial and Channel  Squeeze & Excitation in Fully Convolutional Networks.pdf\n",
    "    #https://github.com/Youngkl0726/Convolutional-Block-Attention-Module/blob/master/CBAMNet.py\n",
    "    #https://github.com/kobiso/CBAM-keras/blob/master/models/attention_module.py\n",
    "    def __init__(self,\n",
    "                 feature_net='se_resnext50_32x4d',\n",
    "                 attention_type=None,\n",
    "                 reduction=16,\n",
    "                 pretrained_file=None,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.attention = attention_type is not None\n",
    "        self.attention_type = attention_type\n",
    "        decoder_kernels = [1, 1, 1, 1, 1]\n",
    "        if feature_net == 'se_resnext50_32x4d':\n",
    "            self.backbone = se_resnext50_32x4d()\n",
    "            self.EX = 4\n",
    "        if feature_net == 'se_resnext101_32x4d':\n",
    "            self.backbone = se_resnext101_32x4d()\n",
    "            self.EX = 4\n",
    "        elif feature_net == 'se_resnet50':\n",
    "            self.backbone = se_resnet50()\n",
    "            self.EX = 4\n",
    "        elif feature_net == 'se_resnet101':\n",
    "            self.backbone = se_resnet101()\n",
    "            self.EX = 4\n",
    "        elif feature_net == 'se_resnet152':\n",
    "            self.backbone = se_resnet152()\n",
    "            self.EX = 4\n",
    "        elif feature_net == 'senet154':\n",
    "            self.backbone = senet154()\n",
    "            self.EX = 4\n",
    "\n",
    "        self.load_pretrain(pretrained_file)\n",
    "        self.conv1 =nn.Sequential(*list(self.backbone.layer0.children())[:-1])\n",
    "        self.encoder2 = self.backbone.layer1  # 64*self.EX\n",
    "        self.encoder3 = self.backbone.layer2  # 128*self.EX\n",
    "        self.encoder4 = self.backbone.layer3  # 256*self.EX\n",
    "        self.encoder5 = self.backbone.layer4  # 512*self.EX\n",
    "        self.center = nn.Sequential(\n",
    "            ConvBn2d(512*self.EX, 512*self.EX, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ConvBn2d(512*self.EX, 256*self.EX, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        att_type=self.attention_type\n",
    "        self.decoder5 = Decoder(512*self.EX + 256*self.EX, 512, 32,\n",
    "                                attention_type=att_type,\n",
    "                                attention_kernel_size=decoder_kernels[0],\n",
    "                                reduction=reduction)\n",
    "        self.decoder4 = Decoder(256*self.EX + 32, 256, 32,\n",
    "                                attention_type=att_type,\n",
    "                                attention_kernel_size=decoder_kernels[1],\n",
    "                                reduction=reduction)\n",
    "        self.decoder3 = Decoder(128*self.EX + 32, 128, 32,\n",
    "                                attention_type=att_type,\n",
    "                                attention_kernel_size=decoder_kernels[2],\n",
    "                                reduction=reduction)\n",
    "        self.decoder2 = Decoder(64*self.EX + 32, 64, 32,\n",
    "                                attention_type=att_type,\n",
    "                                attention_kernel_size=decoder_kernels[3],\n",
    "                                reduction=reduction)\n",
    "        self.decoder1 = Decoder(32, 32, 32,\n",
    "                                attention_type=att_type,\n",
    "                                attention_kernel_size=decoder_kernels[4],\n",
    "                                reduction=reduction)\n",
    "        self.logit = nn.Sequential(\n",
    "            ConvBnRelu2d(160, 64, kernel_size=3, padding=1),\n",
    "            ConvBnRelu2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(32, 4, kernel_size=1, padding=0),\n",
    "        )\n",
    "    def forward(self, x, *args):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        e2 = self.encoder2(x)\n",
    "        e3 = self.encoder3(e2)\n",
    "        e4 = self.encoder4(e3)\n",
    "        e5 = self.encoder5(e4)\n",
    "\n",
    "        f = self.center(e5)\n",
    "        d5 = self.decoder5(torch.cat([f, e5], 1))\n",
    "        d4 = self.decoder4(torch.cat([d5, e4], 1))\n",
    "        d3 = self.decoder3(torch.cat([d4, e3], 1))\n",
    "        d2 = self.decoder2(torch.cat([d3, e2], 1))\n",
    "        d1 = self.decoder1(d2)\n",
    "\n",
    "        f = torch.cat((\n",
    "                 d1,\n",
    "                 F.upsample(d2, scale_factor=2, mode='bilinear',align_corners=False),\n",
    "                 F.upsample(d3, scale_factor=4, mode='bilinear', align_corners=False),\n",
    "                 F.upsample(d4, scale_factor=8, mode='bilinear', align_corners=False),\n",
    "                 F.upsample(d5, scale_factor=16, mode='bilinear', align_corners=False),\n",
    "\n",
    "        ), 1)\n",
    "\n",
    "        logit = self.logit(f)\n",
    "        return logit\n",
    "\n",
    "def unet_se_resnext50_cbam_v0a(**kwargs):\n",
    "    pretrained_file = kwargs['pretrained_file']\n",
    "    model = SEnetUnet(feature_net='se_resnext50_32x4d', attention_type='cbam_v0a', pretrained_file=pretrained_file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_length_encode(component):\n",
    "    if component.sum() == 0:\n",
    "        return ''\n",
    "    component = np.hstack([np.array([0]), component.T.flatten(), np.array([0])])\n",
    "    start  = np.where(component[1: ] > component[:-1])[0]\n",
    "    end    = np.where(component[:-1] > component[1: ])[0]\n",
    "    length = end-start\n",
    "      \n",
    "    rle = []\n",
    "    for i in range(len(length)):\n",
    "        if i==0:\n",
    "            rle.extend([start[0], length[0]])\n",
    "        else:\n",
    "            rle.extend([start[i], length[i]])\n",
    "\n",
    "    rle = ' '.join([str(r) for r in rle])\n",
    "    return rle\n",
    "\n",
    "def run_length_decode(rle, height=256, width=1600, fill_value=1.):\n",
    "    component = np.zeros((height, width), np.float32)\n",
    "    if str(rle) == 'nan' or rle == 0:\n",
    "        return component\n",
    "    component = component.reshape(-1)\n",
    "    rle  = np.array([int(s) for s in rle.split(' ')])\n",
    "    rle  = rle.reshape(-1, 2)\n",
    "    start = 0\n",
    "    for index,length in rle:\n",
    "        start = index\n",
    "        end   = start+length\n",
    "        component[start : end] = fill_value\n",
    "        start = end\n",
    "\n",
    "    component = component.reshape(width, height).T\n",
    "    return component\n",
    "\n",
    "def build_mask(s, height, width):\n",
    "    mask = np.zeros((height, width, 4))\n",
    "    for i in range(4):\n",
    "        mask[:,:,i] = run_length_decode(s[f'{i+1}'], height, width)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = {\n",
    "    'unet_resnet34_cbam_v0a': 'resnet34-333f7ec4.pth',\n",
    "    'unet_se_resnext50_cbam_v0a': 'se_resnext50_32x4d-a260b3a4.pth',\n",
    "}\n",
    "\n",
    "def init_network(params):\n",
    "    architecture = params.get('architecture', 'unet_resnet34_cbam_v0a')\n",
    "    pretrained_file = opj(PRETRAINED_DIR, model_names[architecture])\n",
    "    print(\">> Using pre-trained model.\")\n",
    "    net = eval(architecture)(pretrained_file=pretrained_file)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_tensor(image, mean=0, std=1.):\n",
    "    image = image.astype(np.float32)\n",
    "    image = (image-mean)/std\n",
    "    if len(image.shape) == 3:\n",
    "        image = image.transpose((2,0,1))\n",
    "    tensor = torch.from_numpy(image)\n",
    "\n",
    "    return tensor\n",
    "\n",
    "def label_to_tensor(label):\n",
    "    label_ret = label.astype(np.float32)\n",
    "    label_ret = (label_ret > 0.1).astype(np.float32)\n",
    "    if len(label_ret.shape) == 3:\n",
    "        label_ret = label_ret.transpose((2,0,1)) \n",
    "    tensor = torch.from_numpy(label_ret).type(torch.FloatTensor)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteelDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 steel_df,\n",
    "                 img_size=(256, 1600),\n",
    "                 mask_size=(256, 1600),\n",
    "                 transform=None,\n",
    "                 return_label=True,\n",
    "                 pseudo=None,\n",
    "                 pseudo_ratio=0.,\n",
    "                 crop_version=None,\n",
    "                 dataset=None,\n",
    "                 predict_pos=False):\n",
    "        self.img_size = img_size\n",
    "        self.mask_size = mask_size\n",
    "        self.return_label = return_label\n",
    "        self.crop_version = crop_version\n",
    "        self.dataset = dataset\n",
    "        self.suffix = 'jpg'\n",
    "       \n",
    "        base_dir = DATA_DIR\n",
    "        if dataset in ['train', 'val']:\n",
    "            if crop_version is None:\n",
    "                img_dir = opj(base_dir, 'train', 'images', 'images_256x1600')\n",
    "                print(img_dir)\n",
    "        elif dataset in ['test']:\n",
    "            if crop_version is None:\n",
    "                img_dir = opj(base_dir, 'test', 'images', 'images_256x1600')\n",
    "        else:\n",
    "            raise ValueError(dataset)\n",
    "\n",
    "        if predict_pos:\n",
    "            steel_df = steel_df[steel_df[STEEL] == 1]\n",
    "        steel_df = steel_df.fillna(0)\n",
    "        steel_df['pseudo'] = False\n",
    "        self.steel_df = steel_df\n",
    "\n",
    "        if crop_version is None:\n",
    "            self.img_ids = self.steel_df[ID].values\n",
    "        else:\n",
    "            self.img_ids = self.steel_df[CROP_ID].values\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.num = len(self.img_ids)\n",
    "\n",
    "        self.basic_img_ids = self.img_ids\n",
    "        self.transform = transform\n",
    "\n",
    "        # self.pseudo_flag = self.steel_df['pseudo'].values\n",
    "        # self.basic_pseudo_flag = self.pseudo_flag\n",
    "        # self.pseudo = pseudo\n",
    "        # self.pseudo_ratio = pseudo_ratio\n",
    "\n",
    "        if (dataset == 'train') and return_label:\n",
    "            if 'pos' in self.steel_df.columns:\n",
    "                self.pos_flag = self.steel_df['pos']\n",
    "                self.pos_steel_df = self.steel_df[self.pos_flag]\n",
    "                self.neg_steel_df = self.steel_df[~self.pos_flag]\n",
    "            else:\n",
    "                self.pos_flag = self.steel_df[SPLIT] != 0\n",
    "                self.pos_steel_df = self.steel_df[self.pos_flag]\n",
    "                self.neg_steel_df = self.steel_df[~self.pos_flag]\n",
    "        else:\n",
    "            self.pos_steel_df = None\n",
    "            self.neg_steel_df = None\n",
    "\n",
    "        # if pseudo is not None:\n",
    "        #     self.pseudo_list = pseudo.split(',')\n",
    "        #     self.pos_pseudo_df_list = []\n",
    "        #     self.neg_pseudo_df_list = []\n",
    "        #     for pseudo in self.pseudo_list:\n",
    "        #         pseudo_df = pd.read_csv(opj(DATA_DIR, 'pseudo', '%s.csv' % pseudo))\n",
    "        #         pseudo_df['pseudo'] = True\n",
    "        #         if CROP_ID not in pseudo_df.columns:\n",
    "        #             pseudo_df[CROP_ID] = pseudo_df[ID]\n",
    "        #         if 'chexpert' in pseudo:\n",
    "        #             pseudo_df['suffix'] = 'jpg'\n",
    "        #         else:\n",
    "        #             pseudo_df['suffix'] = 'png'\n",
    "        #         pseudo_df['pseudo_name'] = pseudo\n",
    "        #         pos_pseudo_df = pseudo_df[pseudo_df[SPLIT] != '-1']\n",
    "        #         neg_pseudo_df = pseudo_df[pseudo_df[SPLIT] == '-1']\n",
    "\n",
    "        #         self.pos_pseudo_df_list.append(pos_pseudo_df)\n",
    "        #         self.neg_pseudo_df_list.append(neg_pseudo_df)\n",
    "        #     self.resample_pseudo(first=True)\n",
    "\n",
    "        print('image_dir: %s' % self.img_dir)\n",
    "        print('image size: %s' % str(self.img_size))\n",
    "\n",
    "    def resample_pseudo(self, first=False):\n",
    "        steel_df_list = [self.pos_steel_df, self.neg_steel_df]\n",
    "        if first:\n",
    "            print('%s pos_num: %d neg_num: %d' % ('train', len(steel_df_list[-2]), len(steel_df_list[-1])))\n",
    "\n",
    "        for idx, (pos_pseudo_df, neg_pseudo_df) in enumerate(zip(self.pos_pseudo_df_list, self.neg_pseudo_df_list)):\n",
    "            pos_pseudo_size = int(min(len(self.pos_steel_df) * self.pseudo_ratio, len(pos_pseudo_df)))\n",
    "            neg_pseudo_size = int(min(len(self.neg_steel_df) / len(self.pos_steel_df) * pos_pseudo_size, len(neg_pseudo_df)))\n",
    "\n",
    "            pos_pseudo_size = min(len(pos_pseudo_df), pos_pseudo_size)\n",
    "            neg_pseudo_size = min(len(neg_pseudo_df), neg_pseudo_size)\n",
    "            steel_df_list.append(pos_pseudo_df.iloc[np.random.choice(len(pos_pseudo_df), size=pos_pseudo_size, replace=False)])\n",
    "            steel_df_list.append(neg_pseudo_df.iloc[np.random.choice(len(neg_pseudo_df), size=neg_pseudo_size, replace=False)])\n",
    "\n",
    "            if first:\n",
    "                if self.crop_version is None:\n",
    "                    print('pseudo dir: %s' % opj(DATA_DIR, pos_pseudo_df.iloc[0][DATASET],\n",
    "                                                 'images', 'images_%d' % self.img_size))\n",
    "                else:\n",
    "                    print('pseudo dir: %s' % opj(DATA_DIR, pos_pseudo_df.iloc[0][DATASET],\n",
    "                                                 'images', 'images_%s_%d' % (self.crop_version, self.img_size)))\n",
    "                print('%s pos_num: %d neg_num: %d' % (self.pseudo_list[idx], len(steel_df_list[-2]), len(steel_df_list[-1])))\n",
    "\n",
    "        steel_df = pd.concat(steel_df_list)\n",
    "        if self.crop_version is None:\n",
    "            self.img_ids = steel_df[ID].values\n",
    "        else:\n",
    "            self.img_ids = steel_df[CROP_ID].values\n",
    "        self.pseudo_flag = steel_df['pseudo'].values\n",
    "        self.dataset = steel_df[DATASET].values\n",
    "        self.pos_flag = steel_df[SPLIT] != 0\n",
    "        self.pseudo_suffix = steel_df['suffix'].values\n",
    "        self.pseudo_name = steel_df['pseudo_name'].values\n",
    "        self.num = len(self.img_ids)\n",
    "\n",
    "    def resample(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # is_pseudo = self.pseudo_flag[index]\n",
    "        img_id = self.img_ids[index]\n",
    "\n",
    "        # if is_pseudo:\n",
    "        #     dataset = self.dataset[index]\n",
    "        #     pseudo_suffix = self.pseudo_suffix[index]\n",
    "        #     if self.crop_version is None:\n",
    "        #         img_fname = opj(DATA_DIR, dataset, 'images', 'images_1024',\n",
    "        #                         '%s.%s' % (img_id, pseudo_suffix))\n",
    "        #     else:\n",
    "        #         img_fname = opj(DATA_DIR, dataset, 'images', 'images_%s' % self.crop_version,\n",
    "        #                         '%s.%s' % (img_id, pseudo_suffix))\n",
    "        # else:\n",
    "        #     img_fname = opj(self.img_dir, '%s.%s' % (img_id, self.suffix))\n",
    "        img_fname = opj(self.img_dir, f'{img_id}')\n",
    "\n",
    "        image = cv2.imread(img_fname)\n",
    "        if image is None:\n",
    "            print(img_fname)\n",
    "        #if image.shape[0] != self.img_size[0] or image.shape[1] != self.img_size[1]:\n",
    "        #    image = cv2.resize(image, (self.img_size[0], self.img_size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        if self.return_label:\n",
    "            # if is_pseudo:\n",
    "            #     dataset = self.dataset[index]\n",
    "            #     pseudo_name = self.pseudo_name[index]\n",
    "            #     if self.crop_version is None:\n",
    "            #         mask_file = opj(DATA_DIR, dataset, 'images', 'masks_1024', '%s.png' % img_id)\n",
    "            #     else:\n",
    "            #         if pseudo_name is not None and '8740_pseudo' in pseudo_name:\n",
    "            #             mask_file = opj(DATA_DIR, dataset, 'images', 'masks_8740_%s' % self.crop_version,\n",
    "            #                             '%s.png' % img_id)\n",
    "            #         else:\n",
    "            #             mask_file = opj(DATA_DIR, dataset, 'images', 'masks_%s' % self.crop_version,\n",
    "            #                             '%s.png' % img_id)\n",
    "            # else:\n",
    "            #     mask_file = opj(self.mask_dir, '%s.png' % img_id)\n",
    "            \n",
    "            mask = build_mask(self.steel_df.iloc[index], self.mask_size[0], self.mask_size[1])\n",
    "            mask = mask.astype(np.int8)\n",
    "\n",
    "            if self.transform is not None:\n",
    "                image, mask = self.transform(image=image, mask=mask)\n",
    "\n",
    "            image = image / 255.0\n",
    "            # mask = mask / 255.0\n",
    "            image = image_to_tensor(image)\n",
    "            mask = label_to_tensor(mask)\n",
    "\n",
    "            return image, mask, index\n",
    "        else:\n",
    "            if self.transform is not None:\n",
    "                image = self.transform(image=image)[0]\n",
    "\n",
    "            image = image / 255.0\n",
    "\n",
    "            image = image_to_tensor(image)\n",
    "            return image, index\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num\n",
    "\n",
    "\n",
    "# https://www.kaggle.com/c/siim-acr-STEEL-segmentation/discussion/97456\n",
    "class BalanceClassSampler(Sampler):\n",
    "    def __init__(self, dataset, length=None):\n",
    "        self.dataset = dataset\n",
    "        if length is None:\n",
    "            length = len(self.dataset)\n",
    "        self.length = int(length)\n",
    "\n",
    "        half = self.length // 2 + 1\n",
    "        self.pos_length = half\n",
    "        self.neg_length = half\n",
    "        print('pos num: %s, neg num: %s' % (self.pos_length, self.neg_length))\n",
    "\n",
    "    def __iter__(self):\n",
    "        pos_index = np.where(self.dataset.pos_flag)[0]\n",
    "        neg_index = np.where(~self.dataset.pos_flag)[0]\n",
    "\n",
    "        pos = np.random.choice(pos_index, self.pos_length, replace=True)\n",
    "        neg = np.random.choice(neg_index, self.neg_length, replace=True)\n",
    "\n",
    "        l = np.hstack([pos, neg]).T\n",
    "        l = l.reshape(-1)\n",
    "        np.random.shuffle(l)\n",
    "        l = l[:self.length]\n",
    "        return iter(l)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Lovasz-Softmax and Jaccard hinge loss in PyTorch\n",
    "Maxim Berman 2018 ESAT-PSI KU Leuven (MIT License)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function, division\n",
    "try:\n",
    "    from itertools import  ifilterfalse\n",
    "except ImportError: # py3k\n",
    "    from itertools import  filterfalse\n",
    "\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    p = len(gt_sorted)\n",
    "    gts = gt_sorted.sum()\n",
    "    intersection = gts - gt_sorted.float().cumsum(0)\n",
    "    union = gts + (1 - gt_sorted).float().cumsum(0)\n",
    "    jaccard = 1. - intersection / union\n",
    "    if p > 1: # cover 1-pixel case\n",
    "        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n",
    "    return jaccard\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n",
    "                    for log, lab in zip(logits, labels))\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "    if len(labels) == 0:\n",
    "        # only void pixels, the gradients should be 0\n",
    "        return logits.sum() * 0.\n",
    "    signs = 2. * labels.float() - 1.\n",
    "    errors = (1. - logits * Variable(signs))\n",
    "    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n",
    "    perm = perm.data\n",
    "    gt_sorted = labels[perm]\n",
    "    grad = lovasz_grad(gt_sorted)\n",
    "    # loss = torch.dot(F.elu(errors_sorted)+1, Variable(grad))\n",
    "    loss = torch.dot(F.relu(errors_sorted), Variable(grad))\n",
    "    return loss\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = scores.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = (labels != ignore)\n",
    "    vscores = scores[valid]\n",
    "    vlabels = labels[valid]\n",
    "    return vscores, vlabels\n",
    "\n",
    "def mean(l, ignore_nan=False, empty=0):\n",
    "    \"\"\"\n",
    "    nanmean compatible with generators.\n",
    "    \"\"\"\n",
    "    l = iter(l)\n",
    "    if ignore_nan:\n",
    "        l = ifilterfalse(np.isnan, l)\n",
    "    try:\n",
    "        n = 1\n",
    "        acc = next(l)\n",
    "    except StopIteration:\n",
    "        if empty == 'raise':\n",
    "            raise ValueError('Empty mean')\n",
    "        return empty\n",
    "    for n, v in enumerate(l, 2):\n",
    "        acc += v\n",
    "    if n == 1:\n",
    "        return acc\n",
    "    return acc / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(prob, truth, threshold=0.5):\n",
    "    num = prob.size(0)\n",
    "\n",
    "    prob = prob > threshold\n",
    "    truth = truth > 0.5\n",
    "\n",
    "    prob = prob.view(num, -1)\n",
    "    truth = truth.view(num, -1)\n",
    "    intersection = (prob * truth)\n",
    "\n",
    "    score = 2. * (intersection.sum(1) + 1.).float() / (prob.sum(1) + truth.sum(1) + 2.).float()\n",
    "    score[score >= 1] = 1\n",
    "    score = score.sum() / num\n",
    "    return score\n",
    "\n",
    "\n",
    "class SymmetricLovaszLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(SymmetricLovaszLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, logits, targets):\n",
    "        return ((L.lovasz_hinge(logits, targets, per_image=True)) + (L.lovasz_hinge(-logits, 1-targets, per_image=True))) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_kaggle_metric(predict, truth, threshold=0.5):\n",
    "    num = len(predict)\n",
    "\n",
    "    prob = predict > threshold\n",
    "    truth = truth > 0.5\n",
    "\n",
    "    prob = prob.reshape(num, -1)\n",
    "    truth = truth.reshape(num, -1)\n",
    "    intersection = (prob * truth)\n",
    "\n",
    "    score = 2. * (intersection.sum(1) + EPS) / (prob.sum(1) + truth.sum(1) + EPS)\n",
    "    score[score >= 1] = 1\n",
    "    return score\n",
    "\n",
    "def get_batch_kaggle_score(param):\n",
    "    df_submit, ids, start, batch_size = param\n",
    "    end = np.minimum(start + batch_size, len(ids))\n",
    "    N = end - start\n",
    "    predict = np.zeros((N,IMG_SIZE,IMG_SIZE),np.bool)\n",
    "    truth   = np.zeros((N,IMG_SIZE,IMG_SIZE),np.bool)\n",
    "    for i,n in enumerate(range(start, end)):\n",
    "        id = ids[n]\n",
    "        p = df_submit.loc[id][TARGET+'_pred']\n",
    "        t = df_submit.loc[id][TARGET]\n",
    "        p = run_length_decode(p,fill_value=1)\n",
    "        t = run_length_decode(t,fill_value=1)\n",
    "        predict[i] = p\n",
    "        truth[i] = t\n",
    "    score = do_kaggle_metric(predict, truth, threshold=0.5)\n",
    "    return score\n",
    "\n",
    "def get_kaggle_score(df_submit, df_truth=None, result_type='val', pool=None, return_mean=True):\n",
    "    if df_truth is None:\n",
    "        if result_type == 'val':\n",
    "            df_truth = pd.read_csv(opj(DATA_DIR, 'meta', 'train-rle.csv'))\n",
    "        else:\n",
    "            return 0.\n",
    "\n",
    "    df_submit = df_submit.merge(df_truth, how='left', on=ID, suffixes=('_pred', ''))\n",
    "    ids = df_submit[ID].values\n",
    "    df_submit = df_submit.set_index(ID).fillna('-1')\n",
    "\n",
    "    batch_size = 100000\n",
    "    N = len(ids)\n",
    "    iter_count = int(np.ceil(N / batch_size))\n",
    "    params = []\n",
    "    for it in range(iter_count):\n",
    "        start = it * batch_size\n",
    "        params.append((df_submit, ids, start, batch_size))\n",
    "\n",
    "    score = get_batch_kaggle_score(params[0])\n",
    "    if return_mean:\n",
    "        score_mean = np.mean(score)\n",
    "        return score_mean\n",
    "    else:\n",
    "        return score, ids\n",
    "\n",
    "def get_kaggle_score_prob(prob_submit, image_ids):\n",
    "\n",
    "    df_truth = pd.read_csv(opj(DATA_DIR, 'meta', 'train-rle.csv'))\n",
    "    ids_submit = pd.DataFrame(image_ids, columns=[ID])\n",
    "    ids_submit = ids_submit.merge(df_truth, how='left', on=ID)\n",
    "    ids_submit = ids_submit.set_index(ID).fillna('-1')\n",
    "    prob_truth = np.zeros((len(ids_submit), IMG_SIZE, IMG_SIZE), np.bool)\n",
    "    for i, t in enumerate(ids_submit[TARGET].values):\n",
    "        t = run_length_decode(t, fill_value=1)\n",
    "        prob_truth[i] = t\n",
    "    score = np.mean(do_kaggle_metric(prob_submit, prob_truth))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(object):\n",
    "    def __init__(self):\n",
    "        self.terminal = sys.stdout\n",
    "        self.file = None\n",
    "\n",
    "    def open(self, file, mode=None):\n",
    "        if mode is None: mode ='w'\n",
    "        self.file = open(file, mode)\n",
    "\n",
    "    def write(self, message, is_terminal=1, is_file=1):\n",
    "        if '\\r' in message: is_file = 0\n",
    "\n",
    "        if is_terminal == 1:\n",
    "            self.terminal.write(message)\n",
    "            self.terminal.flush()\n",
    "\n",
    "        if is_file == 1:\n",
    "            self.file.write(message)\n",
    "            self.file.flush()\n",
    "\n",
    "    def flush(self):       \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    log_out_dir = opj(RESULT_DIR, 'logs', config['out_dir'])\n",
    "    if not ope(log_out_dir):\n",
    "        os.makedirs(log_out_dir)\n",
    "    log = Logger()\n",
    "    log.open(opj(log_out_dir, 'log.train.txt'), mode='a')\n",
    "\n",
    "    model_out_dir = opj(RESULT_DIR, 'models', config['out_dir'])\n",
    "    log.write(\">> Creating directory if it does not exist:\\n>> '{}'\\n\".format(model_out_dir))\n",
    "    if not ope(model_out_dir):\n",
    "        os.makedirs(model_out_dir)\n",
    "\n",
    "    # set cuda visible device\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = config['gpu_id']\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    # set random seeds\n",
    "    torch.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    model_params = {}\n",
    "    model_params['architecture'] = config['arch']\n",
    "    model = init_network(model_params)\n",
    "\n",
    "    # move network to gpu\n",
    "    model = DataParallel(model)\n",
    "    model.cuda()\n",
    "\n",
    "    if config['ema']:\n",
    "        ema_model = copy.deepcopy(model)\n",
    "        ema_model.cuda()\n",
    "    else:\n",
    "        ema_model = None\n",
    "\n",
    "    # define loss function (criterion)\n",
    "    try:\n",
    "        criterion = eval(config['loss'])().cuda()\n",
    "    except:\n",
    "        raise(RuntimeError(\"Loss {} not available!\".format(config['loss'])))\n",
    "\n",
    "    start_epoch = 0\n",
    "    best_epoch = 0\n",
    "    best_dice = 0\n",
    "    best_dice_arr = np.zeros(3)\n",
    "\n",
    "    # define scheduler\n",
    "    try:\n",
    "        scheduler = eval(config['scheduler'])()\n",
    "    except:\n",
    "        raise (RuntimeError(\"Scheduler {} not available!\".format(config['scheduler'])))\n",
    "    optimizer = scheduler.schedule(model, start_epoch, config['epochs'])[0]\n",
    "\n",
    "    # optionally resume from a checkpoint\n",
    "    if config['resume']:\n",
    "        model_fpath = os.path.join(model_out_dir, config['resume'])\n",
    "        if os.path.isfile(model_fpath):\n",
    "            # load checkpoint weights and update model and optimizer\n",
    "            log.write(\">> Loading checkpoint:\\n>> '{}'\\n\".format(model_fpath))\n",
    "\n",
    "            checkpoint = torch.load(model_fpath)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_epoch = checkpoint['best_epoch']\n",
    "            best_dice_arr = checkpoint['best_dice_arr']\n",
    "            best_dice = np.max(best_dice_arr)\n",
    "            model.module.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "            optimizer_fpath = model_fpath.replace('.pth', '_optim.pth')\n",
    "            if ope(optimizer_fpath):\n",
    "                log.write(\">> Loading checkpoint:\\n>> '{}'\\n\".format(optimizer_fpath))\n",
    "                optimizer.load_state_dict(torch.load(optimizer_fpath)['optimizer'])\n",
    "\n",
    "            if config['ema']:\n",
    "                ema_model_fpath = model_fpath.replace('.pth', '_ema.pth')\n",
    "                if ope(ema_model_fpath):\n",
    "                    log.write(\">> Loading checkpoint:\\n>> '{}'\\n\".format(ema_model_fpath))\n",
    "                    ema_model.module.load_state_dict(torch.load(ema_model_fpath)['state_dict'])\n",
    "            log.write(\">>>> loaded checkpoint:\\n>>>> '{}' (epoch {})\\n\".format(model_fpath, checkpoint['epoch']))\n",
    "        else:\n",
    "            log.write(\">> No checkpoint found at '{}'\\n\".format(model_fpath))\n",
    "\n",
    "    # Data loading code\n",
    "    train_transform = eval(config['train_transform'])\n",
    "    steel_df = pd.read_csv(opj('..', 'input', 'preprocessed_train.csv'))\n",
    "    train_idx, valid_idx, _, _ = train_test_split(\n",
    "                                            steel_df.index, \n",
    "                                            steel_df['split_label'], \n",
    "                                            test_size=0.2, \n",
    "                                            random_state=43)\n",
    "\n",
    "    train_dataset = SteelDataset(\n",
    "        steel_df.iloc[train_idx],\n",
    "        img_size=config['img_size'],\n",
    "        mask_size=config['img_size'],\n",
    "        transform=train_transform,\n",
    "        return_label=True,\n",
    "        crop_version=config['crop_version'],\n",
    "        pseudo=config['pseudo'],\n",
    "        pseudo_ratio=config['pseudo_ratio'],\n",
    "        dataset='train',\n",
    "    )\n",
    "    if config['is_balance']:\n",
    "        train_sampler = BalanceClassSampler(train_dataset, config['sample_times'] * len(train_dataset))\n",
    "    else:\n",
    "        train_sampler = RandomSampler(train_dataset)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        sampler=train_sampler,\n",
    "        batch_size=config['batch_size'],\n",
    "        drop_last=True,\n",
    "        num_workers=config['workers'],\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    valid_dataset = SteelDataset(\n",
    "        steel_df.iloc[valid_idx],\n",
    "        img_size=config['img_size'],\n",
    "        mask_size=config['img_size'],\n",
    "        transform=None,\n",
    "        return_label=True,\n",
    "        crop_version=config['crop_version'],\n",
    "        dataset='val',\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        sampler=SequentialSampler(valid_dataset),\n",
    "        batch_size=max(int(config['batch_size'] // 2), 1),\n",
    "        drop_last=False,\n",
    "        num_workers=config['workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    log.write('** start training here! **\\n')\n",
    "    log.write('\\n')\n",
    "    log.write('epoch    iter      rate     | smooth_loss/dice | valid_loss/dice | best_epoch/best_score |  min \\n')\n",
    "    log.write('------------------------------------------------------------------------------------------------\\n')\n",
    "    start_epoch += 1\n",
    "    for epoch in range(start_epoch, config['epochs'] + 1):\n",
    "        end = time.time()\n",
    "\n",
    "        # set manual seeds per epoch\n",
    "        np.random.seed(epoch)\n",
    "        torch.manual_seed(epoch)\n",
    "        torch.cuda.manual_seed_all(epoch)\n",
    "\n",
    "        # adjust learning rate for each epoch\n",
    "        lr_list = scheduler.step(model, epoch, config['epochs'])\n",
    "        lr = lr_list[0]\n",
    "\n",
    "        # train for one epoch on train set\n",
    "        iter, train_loss, train_dice = train(train_loader, model, ema_model, criterion, optimizer, epoch, lr=lr)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if config['ema']:\n",
    "                valid_loss, valid_dice = validate(valid_loader, ema_model, criterion, epoch)\n",
    "            else:\n",
    "                valid_loss, valid_dice = validate(valid_loader, model, criterion, epoch)\n",
    "\n",
    "        # remember best loss and save checkpoint\n",
    "        is_best = valid_dice >= best_dice\n",
    "        if is_best:\n",
    "            best_epoch = epoch\n",
    "            best_dice = valid_dice\n",
    "\n",
    "        if config['ema']:\n",
    "            save_top_epochs(model_out_dir, ema_model, best_dice_arr, valid_dice,\n",
    "                            best_epoch, epoch, best_dice, ema=True)\n",
    "        best_dice_arr = save_top_epochs(model_out_dir, model, best_dice_arr, valid_dice,\n",
    "                                        best_epoch, epoch, best_dice, ema=False)\n",
    "\n",
    "        print('\\r', end='', flush=True)\n",
    "        log.write('%5.1f   %5d    %0.6f   |  %0.4f  %0.4f  |  %0.4f  %6.4f |  %6.1f     %6.4f    | %3.1f min \\n' % \\\n",
    "                  (epoch, iter + 1, lr, train_loss, train_dice, valid_loss, valid_dice,\n",
    "                   best_epoch, best_dice, (time.time() - end) / 60))\n",
    "\n",
    "        model_name = '%03d' % epoch\n",
    "        if config['ema']:\n",
    "            save_model(ema_model, model_out_dir, epoch, model_name, best_dice_arr, is_best=is_best,\n",
    "                       optimizer=optimizer, best_epoch=best_epoch, best_dice=best_dice, ema=True)\n",
    "        save_model(model, model_out_dir, epoch, model_name, best_dice_arr, is_best=is_best,\n",
    "                   optimizer=optimizer, best_epoch=best_epoch, best_dice=best_dice, ema=False)\n",
    "\n",
    "def train(train_loader, model, ema_model, criterion, optimizer, epoch, lr=1e-5):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    dices = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    if config['pseudo'] is not None and epoch > 1:\n",
    "        train_loader.dataset.resample_pseudo()\n",
    "\n",
    "    num_its = len(train_loader)\n",
    "    end = time.time()\n",
    "    iter = 0\n",
    "    print_freq = 1\n",
    "    for iter, iter_data in enumerate(train_loader, 0):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # zero out gradients so we can accumulate new ones over batches\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        images, masks, indices = iter_data\n",
    "        images = Variable(images.cuda())\n",
    "        masks = Variable(masks.cuda())\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        # loss = criterion(outputs, masks, epoch=epoch)\n",
    "\n",
    "        losses.update(loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), config['clipnorm'])\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        probs = F.sigmoid(outputs)\n",
    "        dice = metric(probs, masks)\n",
    "        dices.update(dice.item())\n",
    "\n",
    "        if config['ema']:\n",
    "            if epoch >= config['ema_start']:\n",
    "                accumulate(ema_model, model, decay=config['ema_decay'])\n",
    "            else:\n",
    "                accumulate(ema_model, model, decay=0)\n",
    "\n",
    "        if (iter + 1) % print_freq == 0 or iter == 0 or (iter + 1) == num_its:\n",
    "            print('\\r%5.1f   %5d    %0.6f   |  %0.4f  %0.4f  | ... ' % \\\n",
    "                  (epoch - 1 + (iter + 1) / num_its, iter + 1, lr, losses.avg, dices.avg), \\\n",
    "                  end='', flush=True)\n",
    "\n",
    "    return iter, losses.avg, dices.avg\n",
    "\n",
    "def validate(valid_loader, model, criterion, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    dices = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for it, iter_data in enumerate(valid_loader, 0):\n",
    "        images, masks, indices = iter_data\n",
    "        images = Variable(images.cuda())\n",
    "        masks = Variable(masks.cuda())\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        # loss = criterion(outputs, masks, epoch=epoch)\n",
    "        probs = F.sigmoid(outputs)\n",
    "        dice = metric(probs, masks)\n",
    "\n",
    "        losses.update(loss.item())\n",
    "        dices.update(dice.item())\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "    return losses.avg, dices.avg\n",
    "\n",
    "def save_model(model, model_out_dir, epoch, model_name, best_dice_arr, is_best=False,\n",
    "               optimizer=None, best_epoch=None, best_dice=None, ema=False):\n",
    "    if type(model) == DataParallel:\n",
    "        state_dict = model.module.state_dict()\n",
    "    else:\n",
    "        state_dict = model.state_dict()\n",
    "    for key in state_dict.keys():\n",
    "        state_dict[key] = state_dict[key].cpu()\n",
    "\n",
    "    if ema:\n",
    "        model_fpath = opj(model_out_dir, '%s_ema.pth' % model_name)\n",
    "    else:\n",
    "        model_fpath = opj(model_out_dir, '%s.pth' % model_name)\n",
    "    torch.save({\n",
    "        'state_dict': state_dict,\n",
    "        'best_epoch': best_epoch,\n",
    "        'epoch': epoch,\n",
    "        'best_dice': best_dice,\n",
    "        'best_dice_arr': best_dice_arr,\n",
    "    }, model_fpath)\n",
    "\n",
    "    optim_fpath = opj(model_out_dir, '%s_optim.pth' % model_name)\n",
    "    if optimizer is not None:\n",
    "        torch.save({\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, optim_fpath)\n",
    "\n",
    "    if is_best:\n",
    "        if ema:\n",
    "            best_model_fpath = opj(model_out_dir, 'final_ema.pth')\n",
    "        else:\n",
    "            best_model_fpath = opj(model_out_dir, 'final.pth')\n",
    "        shutil.copyfile(model_fpath, best_model_fpath)\n",
    "        if optimizer is not None:\n",
    "            best_optim_fpath = opj(model_out_dir, 'final_optim.pth')\n",
    "            shutil.copyfile(optim_fpath, best_optim_fpath)\n",
    "\n",
    "def metric(logit, truth, threshold=0.5):\n",
    "    dice = dice_score(logit, truth, threshold=threshold)\n",
    "    return dice\n",
    "\n",
    "def accumulate(model1, model2, decay=0.99):\n",
    "    par1 = model1.state_dict()\n",
    "    par2 = model2.state_dict()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for k in par1.keys():\n",
    "            par1[k].data.copy_(par1[k].data * decay + par2[k].data * (1 - decay))\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0.\n",
    "        self.avg = 0.\n",
    "        self.sum = 0.\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def save_top_epochs(model_out_dir, model, best_dice_arr, valid_dice, best_epoch, epoch, best_dice, ema=False):\n",
    "    best_dice_arr = best_dice_arr.copy()\n",
    "\n",
    "    if ema:\n",
    "        suffix = '_ema'\n",
    "    else:\n",
    "        suffix = ''\n",
    "    min_dice = np.min(best_dice_arr)\n",
    "    last_ix = len(best_dice_arr) - 1\n",
    "\n",
    "    def get_top_path(ix):\n",
    "        return opj(model_out_dir, 'top%d%s.pth' % (ix + 1, suffix))\n",
    "\n",
    "    if valid_dice > min_dice:\n",
    "        min_ix = last_ix\n",
    "        for ix, score in enumerate(best_dice_arr):\n",
    "            if score < valid_dice:\n",
    "                min_ix = ix\n",
    "                break\n",
    "\n",
    "        lowest_path = get_top_path(last_ix)\n",
    "        if ope(lowest_path):\n",
    "            os.remove(lowest_path)\n",
    "\n",
    "        for ix in range(last_ix - 1, min_ix - 1, -1):\n",
    "            score = best_dice_arr[ix]\n",
    "            best_dice_arr[ix + 1] = score\n",
    "            if score > 0 and ope(get_top_path(ix)):\n",
    "                os.rename(get_top_path(ix), get_top_path(ix + 1))\n",
    "\n",
    "        best_dice_arr[min_ix] = valid_dice\n",
    "\n",
    "        model_name = 'top%d' % (min_ix + 1)\n",
    "        save_model(model, model_out_dir, epoch, model_name, best_dice_arr, is_best=False,\n",
    "                   optimizer=None, best_epoch=best_epoch, best_dice=best_dice, ema=ema)\n",
    "\n",
    "    return best_dice_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling main function ... \n",
      "\n",
      ">> Creating directory if it does not exist:\n",
      ">> '../output/result/models/.'\n",
      ">> Using pre-trained model.\n",
      "load pretrained file: ../input/pretrained/resnet34-333f7ec4.pth\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/pretrained/resnet34-333f7ec4.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-532dc484ff70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'calling main function ... \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nsuccess!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-d844ed483f4c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmodel_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmodel_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'architecture'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# move network to gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-3e201ac26680>\u001b[0m in \u001b[0;36minit_network\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpretrained_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPRETRAINED_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">> Using pre-trained model.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-d78d006b1495>\u001b[0m in \u001b[0;36munet_resnet34_cbam_v0a\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munet_resnet34_cbam_v0a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mpretrained_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pretrained_file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResnetUnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_net\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'resnet34'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cbam_v0a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-d78d006b1495>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, feature_net, attention_type, reduction, reslink, out_channel, pretrained_file)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_pretrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         self.conv1 = nn.Sequential(\n\u001b[1;32m     37\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-d78d006b1495>\u001b[0m in \u001b[0;36mload_pretrain\u001b[0;34m(self, pretrain_file)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_pretrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrain_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load pretrained file: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpretrain_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrain_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     def __init__(self,feature_net='resnet34',\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/pretrained/resnet34-333f7ec4.pth'"
     ]
    }
   ],
   "source": [
    "print('calling main function ... \\n')\n",
    "main()\n",
    "print('\\nsuccess!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
